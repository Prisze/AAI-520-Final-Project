{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# Set device to CUDA if available, else CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_path = \".....USD\\\\Natural Language Processing\\\\Final Project\\\\Model\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-medium')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Chat class for conversation\n",
    "class Chat:\n",
    "    def __init__(self, chatbot, max_response_len=12):\n",
    "        self.chatbot = chatbot\n",
    "        self.messages = []\n",
    "        self.max_response_len = max_response_len\n",
    "        self.temperature = 0.4  # Default temperature\n",
    "        self.top_p = 0.6  # Default top_p\n",
    "\n",
    "    # (1) Send a message in multi-turn conversation\n",
    "    def send(self, text: str):\n",
    "        # Add user message to the conversation\n",
    "        self.messages.append(f\"User: {text}\")\n",
    "        \n",
    "        # Create the conversation prompt with proper role annotations\n",
    "        prompt = '<|endoftext|>'.join(self.messages) + '<|endoftext|>'\n",
    "        \n",
    "        # Trim history if too long (keeping recent turns)\n",
    "        max_tokens = 356 # Adjust based on your model's max token limit\n",
    "        prompt_tokens = self.chatbot.tokenizer.encode(prompt)\n",
    "        if len(prompt_tokens) > max_tokens:\n",
    "            # Keep the most recent context, discard older conversation\n",
    "            prompt_tokens = prompt_tokens[-max_tokens:]\n",
    "            prompt = self.chatbot.tokenizer.decode(prompt_tokens)\n",
    "\n",
    "        # Generate a response, passing the current mood (temperature, top_p)\n",
    "        response = self.chatbot.generate(prompt, max_length=self.max_response_len, temperature=self.temperature, top_p=self.top_p)\n",
    "        \n",
    "        # Add bot response to the conversation\n",
    "        self.messages.append(f\"Bot: {response}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    # (2) Set a specific topic for the conversation\n",
    "    def set_topic(self, topic: str):\n",
    "        self.messages.append(f\"Topic: {topic}\")\n",
    "\n",
    "    # (4) Reset the conversation history\n",
    "    def reset_conversation(self):\n",
    "        self.messages = []\n",
    "\n",
    "    # (5) Set chatbot mood by adjusting temperature and top_p values\n",
    "    def set_mood(self, temperature: float, top_p: float):\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, model_path: str, device=None):\n",
    "        if not device:\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = device\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_path).to(self.device)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-medium')\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    # (3) Generate response based on conversation context and mood\n",
    "    def generate(self, text: str, max_length: int = None, temperature: float = 0.3, top_p: float = 0.7) -> str:\n",
    "        if not max_length:\n",
    "            # Determine max length based on text complexity or conversation context\n",
    "            max_length = min(len(self.tokenizer.encode(text)) // 2, 100)  # Example logic\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "            outputs = self.model.generate(\n",
    "                inputs.input_ids.to(self.device),\n",
    "                attention_mask=inputs.attention_mask.to(self.device),\n",
    "                max_new_tokens=max_length,\n",
    "                no_repeat_ngram_size=5,\n",
    "                early_stopping=True,\n",
    "                num_beams=2,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id,\n",
    "                repetition_penalty=2.0,\n",
    "                temperature=temperature,  # Adjusted mood\n",
    "                top_p=top_p,  # Adjusted mood\n",
    "                do_sample=True,\n",
    "                length_penalty=0.3\n",
    "            )\n",
    "\n",
    "            # Decode response and return\n",
    "            response_outputs = outputs[:, len(inputs['input_ids'][0]):]\n",
    "            response = self.tokenizer.batch_decode(response_outputs, skip_special_tokens=True)[0]\n",
    "            return response\n",
    "\n",
    "    def create_chat(self) -> Chat:\n",
    "        return Chat(self)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Should I excercise daily?\n",
      "Chatbot: Yes, you should. You're going to need a lot\n",
      "User: Thank you\n",
      "Chatbot: I'm not sure what that means but it's the same\n"
     ]
    }
   ],
   "source": [
    "# Load the ChatBot model\n",
    "chatBot = ChatBot(model_path)\n",
    "\n",
    "# Open a new Chat\n",
    "conversation = chatBot.create_chat()\n",
    "# Example usage\n",
    "\n",
    "# Set topic\n",
    "conversation.set_topic(\"Health and Fitness\")\n",
    "\n",
    "# Adjust chatbot mood\n",
    "conversation.set_mood(temperature=0.7, top_p=0.8)\n",
    "\n",
    "# Converse with bot\n",
    "\n",
    "message = 'Should I excercise daily?'\n",
    "print(f'User: {message}')\n",
    "\n",
    "response = conversation.send(message)\n",
    "print(f'Chatbot: {response}')\n",
    "\n",
    "message = 'Thank you'\n",
    "print(f'User: {message}')\n",
    "\n",
    "response = conversation.send(message)\n",
    "print(f'Chatbot: {response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
